{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08bf9693",
   "metadata": {},
   "source": [
    "## Make finegrained labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "124ba7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "import html\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "\n",
    "    inp = re.sub(r'(u/.*? |@.*?( |$))', \"<user> \", text)\n",
    "    inp = re.sub(r'\\u2019', \"'\", inp)\n",
    "    inp = re.sub(r'[“”]', '\"', inp)\n",
    "    inp = re.sub(r'\\\\u[a-f0-9]{4}', \"'\", inp)\n",
    "    inp = re.sub(r'\\(https://.*\\)', \"(URL)\", inp)\n",
    "\n",
    "    inp = re.sub(r'[\\s]{2,}', \" \", inp)\n",
    "    inp = html.unescape(inp).encode('ascii', errors='ignore').decode()\n",
    "        \n",
    "    return inp\n",
    "\n",
    "def process_alpaca(text, label, instruction=None):\n",
    "#     instruction = defs\n",
    "    \n",
    "    out = {'instruction': [],\n",
    "           'input': [],\n",
    "           'output': []\n",
    "          \n",
    "          }\n",
    "    \n",
    "    for i in range(len(text)):\n",
    "        \n",
    "        outp = label[i]\n",
    "        \n",
    "        \n",
    "        inp = clean_text(text[i].strip())\n",
    "        \n",
    "        if type(instruction) is str:\n",
    "            out['instruction'].append(instruction)\n",
    "        elif type(instruction) is list:\n",
    "            out['instruction'].append(instruction[i])\n",
    "            \n",
    "        out['input'].append(inp)\n",
    "        out['output'].append(outp)\n",
    "    return out\n",
    "\n",
    "def openprompt_to_prompt(test_enc):\n",
    "    instructions = []\n",
    "    test_prompt = []\n",
    "    \n",
    "    output = []\n",
    "    \n",
    "    for i in range(len(test_enc)):\n",
    "        ins = '{target} is defined as {target_def}'.format(target=test_enc[i].meta['target'],\n",
    "                                                                         target_def=test_enc[i].meta['definition'])\n",
    "        if test_enc[i].meta['target_groups'] is not None:\n",
    "            ins += 'Target groups include {0}'.format(', '.join(test_enc[i].meta['target_groups']))\n",
    "        instructions.append(ins)\n",
    "        test_prompt.append('Post: {text} Q: Is this post a violation of {target}? Please answer Yes, No, or Unclear. A: '.format(\n",
    "            target=test_enc[i].meta['target'], \n",
    "            target_def=test_enc[i].meta['definition'],\n",
    "            text=test_enc[i].text_a))\n",
    "        \n",
    "        output.append(('Yes' if test_enc[i].label == 2 else ('Unclear' if test_enc[i].label == 1 else 'No')))\n",
    "    return process_alpaca(test_prompt, output, instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "94997179",
   "metadata": {},
   "outputs": [],
   "source": [
    "full = pd.read_csv('data/full_dataset.csv')\n",
    "negative = pd.read_csv('data/negative_for_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "83bf7368",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "enc = tiktoken.encoding_for_model(\"gpt-4\")\n",
    "\n",
    "\n",
    "full['tokens'] = [len(enc.encode(x)) for x in full['text'].to_list()]\n",
    "negative['tokens'] = [len(enc.encode(x)) for x in negative['text'].to_list()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7bfce4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_temp = full[full['tokens'] < 400]\n",
    "to_sample = len(full) - len(full_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "175c6344",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "full = pd.concat([full_temp, negative[(~negative['reddit_id'].isin(full_temp['reddit_id'])) & (negative['tokens'] < 400)].sample(n=to_sample)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2a2ec13c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(      Unnamed: 0.1  Unnamed: 0  \\\n",
       " 0                0           0   \n",
       " 1                1           1   \n",
       " 2                2           2   \n",
       " 3                3           3   \n",
       " 4                4           4   \n",
       " ...            ...         ...   \n",
       " 3072       2664156     2099983   \n",
       " 2119      12612491    11369425   \n",
       " 965       21775426    19221085   \n",
       " 3998      11818772    10687737   \n",
       " 3868      11138731    10118096   \n",
       " \n",
       "                                                    text  original_id  \\\n",
       " 0     Did he kill your sex life? Women are objects s...       1006.0   \n",
       " 1     Don’t support our public schools because child...       1018.0   \n",
       " 2     Tricky Dick. I hope you get hit by a car the n...       1022.0   \n",
       " 3     Canadians are physically and mentally inferior...       1026.0   \n",
       " 4     Is that cat waving a Nazi banner? People with ...       1031.0   \n",
       " ...                                                 ...          ...   \n",
       " 3072  Are you talking about Vital Farms eggs? I love...          NaN   \n",
       " 2119  You got me, I had to find it.  here ya go: \"Th...          NaN   \n",
       " 965   What you are saying is technically true but pr...          NaN   \n",
       " 3998  It will draw some power but you should be fine...          NaN   \n",
       " 3868  No idea if I'm right about this. The mall itse...          NaN   \n",
       " \n",
       "                  label                                           textorig  \\\n",
       " 0             Violates  <p>Did he kill your sex life? Your sense of pr...   \n",
       " 1             Violates  <p>And dark money.  Support our public schools...   \n",
       " 2     Does not violate                                <p>Tricky Dick.</p>   \n",
       " 3             Violates  <p>If anyone out there in Lala Land doesn't be...   \n",
       " 4             Violates  <p>Is that cat waving a Nazi banner? Is its na...   \n",
       " ...                ...                                                ...   \n",
       " 3072  Does not violate                                                NaN   \n",
       " 2119  Does not violate                                                NaN   \n",
       " 965   Does not violate                                                NaN   \n",
       " 3998  Does not violate                                                NaN   \n",
       " 3868  Does not violate                                                NaN   \n",
       " \n",
       "      prev_label                                        finegrained comments  \\\n",
       " 0           NaN  ['TOS_tk', 'HR_ab', 'HR_bc', 'CC_319', 'HR_nt'...      NaN   \n",
       " 1           NaN  ['HR_ab', 'HR_bc', 'HR_nt', 'TOS_met', 'TOS_tw...      NaN   \n",
       " 2           NaN                                                NaN      NaN   \n",
       " 3           NaN  ['TOS_tk', 'HR_ab', 'HR_bc', 'CC_319', 'HR_nt'...      NaN   \n",
       " 4           NaN  ['TOS_tk', 'HR_ab', 'CC_318', 'HR_bc', 'CC_319...      NaN   \n",
       " ...         ...                                                ...      ...   \n",
       " 3072        NaN                                                NaN      NaN   \n",
       " 2119        NaN                                                NaN      NaN   \n",
       " 965         NaN                                                NaN      NaN   \n",
       " 3998        NaN                                                NaN      NaN   \n",
       " 3868        NaN                                                NaN      NaN   \n",
       " \n",
       "       id_x  ...                                       target_group  \\\n",
       " 0      0.0  ...  ['Sex/Gender identity or expression', 'Identit...   \n",
       " 1      1.0  ...                        ['Identity/beliefs', 'Age']   \n",
       " 2      2.0  ...                                                 []   \n",
       " 3      3.0  ...  ['Identity/beliefs', 'National or ethnic origi...   \n",
       " 4      4.0  ...  ['Political belief/association', 'Identity/bel...   \n",
       " ...    ...  ...                                                ...   \n",
       " 3072   NaN  ...                                                NaN   \n",
       " 2119   NaN  ...                                                NaN   \n",
       " 965    NaN  ...                                                NaN   \n",
       " 3998   NaN  ...                                                NaN   \n",
       " 3868   NaN  ...                                                NaN   \n",
       " \n",
       "                  target                                              notes  \\\n",
       " 0     A group/attribute  ['Wilful promotion of hatred', 'degrades women...   \n",
       " 1     A group/attribute  ['This statement exposes children to hatred; \"...   \n",
       " 2         An individual                                                 []   \n",
       " 3     A group/attribute  ['Wilful promotion of hatred', 'Statement asse...   \n",
       " 4     A group/attribute  ['Public incitement of hatred', 'encourages th...   \n",
       " ...                 ...                                                ...   \n",
       " 3072                NaN                                                NaN   \n",
       " 2119                NaN                                                NaN   \n",
       " 965                 NaN                                                NaN   \n",
       " 3998                NaN                                                NaN   \n",
       " 3868                NaN                                                NaN   \n",
       " \n",
       "       source text_type   created_utc          subreddit submission  \\\n",
       " 0     edited       NaN           NaN                NaN        NaN   \n",
       " 1     edited       NaN           NaN                NaN        NaN   \n",
       " 2     edited       NaN           NaN                NaN        NaN   \n",
       " 3     edited       NaN           NaN                NaN        NaN   \n",
       " 4     edited       NaN           NaN                NaN        NaN   \n",
       " ...      ...       ...           ...                ...        ...   \n",
       " 3072  reddit   comment  1.673444e+09  mildlyinteresting    108s07p   \n",
       " 2119  reddit   comment  1.676093e+09              funny    10z963u   \n",
       " 965   reddit   comment  1.685438e+09  NoStupidQuestions    13v6eve   \n",
       " 3998  reddit   comment  1.675759e+09  NoStupidQuestions    10vw8zs   \n",
       " 3868  reddit   comment  1.675457e+09      todayilearned    10spaig   \n",
       " \n",
       "        reddit_id  tokens  \n",
       " 0            NaN      19  \n",
       " 1            NaN      18  \n",
       " 2            NaN      22  \n",
       " 3            NaN      10  \n",
       " 4            NaN      21  \n",
       " ...          ...     ...  \n",
       " 3072  t1_j3w0qvz      57  \n",
       " 2119  t1_j82tr5s      74  \n",
       " 965   t1_jm6idfe     101  \n",
       " 3998  t1_j7jtnut      58  \n",
       " 3868  t1_j73k5mv      51  \n",
       " \n",
       " [2204 rows x 24 columns],\n",
       " 5)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full, to_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59cb705a",
   "metadata": {},
   "outputs": [],
   "source": [
    "full['notes'].isna().sum(), len(full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78c7b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe932ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "legal_defs = pd.read_csv('data/legal definitions.csv')\n",
    "legal_labels = legal_defs['name'].to_list()\n",
    "defs = pd.read_csv('data/definitions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97045278",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = {\n",
    "         'Race (colour, creed)': ['actual and perceived race', 'colour', 'creed', 'race', 'race or perceived race'],\n",
    "         'National or ethnic origin (nationality, ethnicity, ancestry)': ['ancestry', 'ethnic origin', 'ethnicity', 'place of origin', 'national origin', 'national or ethnic origin', 'nationality', 'indigenous identity'],\n",
    "         'Political belief/association': ['political association', 'political belief'],\n",
    "         'Sex/Gender identity or expression': ['gender', 'gender identity', 'gender identity and expression', 'gender identity or expression', 'sex', 'sex/gender'],\n",
    "         'Religion/Religious beliefs': ['religion', 'religious affiliation','religious beliefs' ],\n",
    "         'Sexual orientation': ['sexual orientation'],\n",
    "         'Social condition': ['social condition'],\n",
    "         'Immigration status': ['immigration status'],\n",
    "         'Source of income': ['source of income'],\n",
    "         'Age': ['age'],\n",
    "         'Physical or mental disability': ['physical or mental disability', 'mental or physical disability', 'physical disability', 'mental disability', 'disability', 'pregnancy or disability'],\n",
    "         'Family affiliation': ['family affiliation', 'caste'],\n",
    "         'Conviction that is subject to a pardon or record suspension': ['conviction that is subject to a pardon or record suspension'],\n",
    "         'Receipt of public assistance': ['receipt of public assistance'],\n",
    "         'Serious disease': ['serious disease'],\n",
    "         'Family status': ['family status'],\n",
    "        'Pregnancy': ['pregnancy'],\n",
    "    'Victims of a major violent event and their families/kin': ['victims of a major violent event and their kin', 'victims of a major event and their families'],\n",
    "    'Veteran status': ['veteran status'],\n",
    "    'Marital status': ['marital status']\n",
    "}\n",
    "\n",
    "groups = {x: k for k, v in groups.items() for x in v}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55da3756",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e5e30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# g = set([x.strip().lower() for y in legal_defs['protected_groups'].to_list() for x in y.split(',')])\n",
    "\n",
    "# temp1 = []\n",
    "\n",
    "# for grps in list(g):\n",
    "#     if grps not in groups.keys():\n",
    "#         print(grps)\n",
    "        \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea607ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "legal_defs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f65138",
   "metadata": {},
   "outputs": [],
   "source": [
    "gr = []\n",
    "\n",
    "for i in legal_defs['protected_groups'].to_list():\n",
    "    temp = [groups[x.strip().lower()] for x in i.split(',')]\n",
    "    \n",
    "    gr.append(list(set(temp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab18674f",
   "metadata": {},
   "outputs": [],
   "source": [
    "legal_defs['protected_groups_cleaned'] = gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9143f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "finegrained = []\n",
    "\n",
    "for i in range(len(full)):\n",
    "    label = full.iloc[i]['label']\n",
    "    \n",
    "    if label == 'Violates' and type(full.iloc[i]['target_group']) is list:\n",
    "        temp = []\n",
    "        for g in full.iloc[i]['target_group']:\n",
    "            for j in range(2,len(legal_defs)):\n",
    "                if g in legal_defs.iloc[j]['protected_groups_cleaned']:\n",
    "                    temp.append(legal_labels[j])\n",
    "        \n",
    "        if full.iloc[i]['cc_318']:\n",
    "            temp.append('CC_318')\n",
    "        if full.iloc[i]['cc_319']:\n",
    "            temp.append('CC_319')\n",
    "        print(temp)\n",
    "        finegrained.append(temp)\n",
    "    else:\n",
    "        finegrained.append([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685e614b",
   "metadata": {},
   "outputs": [],
   "source": [
    "full['finegrained'] = [([] if pd.isna(x) else (literal_eval(x) if type(x) is str else x)) for x in full['finegrained'].to_list()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34664cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "full['finegrained'] = [(list(set(finegrained[i] + full['finegrained'].iloc[i])) if full.iloc[i]['label'] == 'Violates' else None) for i in range(len(full))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c33dfc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "full[full['id_x'] == 1006]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2e76e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "full[full['source'] == 'edited']['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39df2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "full.to_csv('data/full_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438ab96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ['{target} states \"{target_def}\" Protected groups include {targets}'.format(\n",
    "    target=legal_defs.iloc[i]['promptName'],\n",
    "    target_def=legal_defs.iloc[i]['definition'],\n",
    "    targets=legal_defs.iloc[i]['protected_groups_cleaned']\n",
    ") for i in range(len(legal_defs))]\n",
    "\n",
    "legal_defs['prompt'] = prompt\n",
    "\n",
    "prompt = '\\n'.join(prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa75735e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping = ['Violates': 'Yes', ]\n",
    "from datasets import Dataset\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "def process_dataset_nonotes(full, legal_defs, name):\n",
    "    for i in range(len(legal_defs)):\n",
    "\n",
    "        inp = ['Post: {text} Q: Is this post a violation of {target}? Please answer Yes, No, or Unclear. A: '.format(\n",
    "                target=legal_defs.iloc[i].promptName, \n",
    "                text=x) for x in full['text'].to_list()]\n",
    "\n",
    "        outp = [('Yes' if (full.iloc[j]['label'] == 'Violates' and legal_labels[i] in full.iloc[j]['finegrained']) else ('Unclear' if full.iloc[j]['label'] == 'Meaning unclear' else 'No')) for j in range(len(full))]\n",
    "\n",
    "    #     for j in range(len(full)):\n",
    "    #         if type(full.iloc[j]['notes']) is list and len(full.iloc[j]['notes']) > 0:\n",
    "\n",
    "        sequences = process_alpaca(text=inp, label=outp, instruction=legal_defs.iloc[i]['prompt'])\n",
    "\n",
    "        Dataset.from_dict(sequences).to_json('{1}/singletarget_nonotes_{0}.json'.format(legal_labels[i], name))\n",
    "        \n",
    "        \n",
    "    prompt = '\\n'.join(legal_defs['prompt'].to_list())\n",
    "    inp = ['Post: {text} Q: Is this post a violation of any of the above policies? Please answer Yes/No and which policies. A: '.format(\n",
    "        target=legal_defs.iloc[i].promptName, \n",
    "        text=x) for x in full['text'].to_list()]\n",
    "\n",
    "    outp = [('Yes' if (full.iloc[j]['label'] == 'Violates' and legal_labels[i] in full.iloc[j]['finegrained']) else ('Unclear' if full.iloc[j]['label'] == 'Meaning unclear' else 'No')) for j in range(len(full))]\n",
    "\n",
    "    #     for j in range(len(full)):\n",
    "    #         if type(full.iloc[j]['notes']) is list and len(full.iloc[j]['notes']) > 0:\n",
    "\n",
    "    sequences = process_alpaca(text=inp, label=outp, instruction=prompt)\n",
    "\n",
    "    Dataset.from_dict(sequences).to_json('{1}/multitarget_nonotes.json'.format(legal_labels[i], name))\n",
    "    \n",
    "def process_dataset_notes(full, legal_defs, name):\n",
    "    for i in range(len(legal_defs)):\n",
    "    \n",
    "        inputs = []\n",
    "\n",
    "        outputs = []\n",
    "\n",
    "        for j in range(len(full)):\n",
    "\n",
    "            inp = 'Post: {text} Q: Is this post a violation of {target}? Please answer Yes, No, or Unclear. A: '.format(\n",
    "                target=legal_defs.iloc[i].promptName, \n",
    "                text=full.iloc[j]['text'])\n",
    "\n",
    "            outp = ('Yes' if (full.iloc[j]['label'] == 'Violates' and legal_labels[i] in full.iloc[j]['finegrained']) else \n",
    "                 ('Unclear' if full.iloc[j]['label'] == 'Meaning unclear' else 'No'))\n",
    "            if type(full.iloc[j]['notes']) is list and len(full.iloc[j]['notes']) > 0:\n",
    "                for note in full.iloc[j]['notes']:\n",
    "                    inputs.append(inp)\n",
    "                    outputs.append(outp + ', {0}'.format(note))\n",
    "            else:\n",
    "                inputs.append(inp)\n",
    "                outputs.append(outp)\n",
    "        sequences = process_alpaca(text=inputs, label=outputs, instruction=legal_defs.iloc[i]['prompt'])\n",
    "\n",
    "        Dataset.from_dict(sequences).to_json('{1}/singletarget_notes_{0}.json'.format(legal_labels[i], name))\n",
    "        \n",
    "    prompt = '\\n'.join(legal_defs['prompt'].to_list())\n",
    "\n",
    "    for j in range(len(full)):\n",
    "\n",
    "        inp = 'Post: {text} Q: Is this post a violation of any of the above policies? Please answer Yes/No and which policies. A: '.format(\n",
    "            target=legal_defs.iloc[i].promptName, \n",
    "            text=full.iloc[j]['text'])\n",
    "\n",
    "        outp = ('Yes' if (full.iloc[j]['label'] == 'Violates' and legal_labels[i] in full.iloc[j]['finegrained']) else \n",
    "             ('Unclear' if full.iloc[j]['label'] == 'Meaning unclear' else 'No'))\n",
    "        if type(full.iloc[j]['notes']) is list and len(full.iloc[j]['notes']) > 0:\n",
    "            for note in full.iloc[j]['notes']:\n",
    "                inputs.append(inp)\n",
    "                outputs.append(outp + ', {0}'.format(note))\n",
    "        else:\n",
    "            inputs.append(inp)\n",
    "            outputs.append(outp)\n",
    "    sequences = process_alpaca(text=inputs, label=outputs, instruction=prompt)\n",
    "\n",
    "    Dataset.from_dict(sequences).to_json('{1}/multitarget_notes.json'.format(legal_labels[i], name))\n",
    "    \n",
    "\n",
    "    \n",
    "def process_dataset(full, legal_defs, name):\n",
    "    \n",
    "    Path(name).mkdir(parents=True, exist_ok=True)\n",
    "    print('directory created (if it didn\\'t already exist)')\n",
    "    print('formatting without notes')\n",
    "    process_dataset_nonotes(full, legal_defs, name)\n",
    "    print('formatting with notes')\n",
    "    process_dataset_notes(full, legal_defs, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae85b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_dataset(full, legal_defs, 'zeroshot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d927399d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = full.groupby('label', group_keys=False).apply(lambda x: x.sample(frac=0.6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f043cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = full[~full.index.isin(train.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5b3974",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b84d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_dataset(train, legal_defs, 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d570c77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_dataset(test, legal_defs, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d38bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('data/legal_train.csv')\n",
    "test.to_csv('data/legal_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62f3cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['text'] = [clean_text(x) for x in train['text'].to_list()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d7afa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['text'] = [clean_text(x) for x in test['text'].to_list()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3961f78a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
