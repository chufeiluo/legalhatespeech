{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_457991/3648894930.py:3: DtypeWarning: Columns (0,1,2,3,4,5,6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('data/reddit_data.csv')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data/reddit_data.csv')\n",
    "gold_data = pd.read_csv('data/full_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "model = SentenceTransformer('multi-qa-mpnet-base-dot-v1').to('cuda')\n",
    "\n",
    "# Two lists of sentences\n",
    "\n",
    "\n",
    "gold_sents = gold_data[gold_data['label'] == 'Violates']['text'].to_list()\n",
    "# gold_sents = gold_data['0'].to_list()\n",
    "\n",
    "#Compute embedding for both lists\n",
    "gold_embed = model.encode(gold_sents, convert_to_tensor=True).to('cuda')\n",
    "\n",
    "to_keep = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    28458925\n",
       "True       553105\n",
       "Name: text, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'].isna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = df[~df['text'].isna()].sample(n=3000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da112cffae6d46b88b5b8201dd9b716d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3000000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "to_keep = []\n",
    "\n",
    "negatives = []\n",
    "\n",
    "thres = 0.55\n",
    "min_thres = 0.3\n",
    "\n",
    "#Compute cosine-similarits\n",
    "for i in tqdm(range(len(df))):\n",
    "    try:\n",
    "        text = model.encode(df['text'].iloc[i],  convert_to_tensor=True).to('cuda')\n",
    "\n",
    "        cosine_scores = util.pytorch_cos_sim(text, gold_embed)\n",
    "    except:\n",
    "        continue\n",
    "    #print(cosine_scores[0])\n",
    "\n",
    "    if max(cosine_scores[0]) > thres:\n",
    "        to_keep.append(i)\n",
    "        if len(to_keep) >= 100000:\n",
    "            break\n",
    "    elif max(cosine_scores[0]) < min_thres:\n",
    "        negatives.append(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 11628)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(to_keep), len(negatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    11628.000000\n",
       "mean       353.375989\n",
       "std        340.312550\n",
       "min          8.000000\n",
       "25%        163.000000\n",
       "50%        263.000000\n",
       "75%        431.000000\n",
       "max       9967.000000\n",
       "Name: text, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[negatives].text.str.len().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "df.iloc[to_keep].to_csv('data/similar_reddit.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_457991/3423515588.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df.iloc[negatives][(df.text.str.len() > 3)].dropna().sample(n=5000).to_csv('data/negative_for_dataset.csv')\n"
     ]
    }
   ],
   "source": [
    "df.iloc[negatives][(df.text.str.len() > 3)].dropna().sample(n=5000).to_csv('data/negative_for_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AmItheAsshole            0.035730\n",
       "AskMen                   0.041248\n",
       "Bad_Cop_No_Donut         0.027778\n",
       "EnoughLibertarianSpam    0.018182\n",
       "Fuckthealtright          0.013477\n",
       "Impeach_Trump            0.025000\n",
       "NoStupidQuestions        0.038508\n",
       "PoliticalHumor           0.020149\n",
       "ShitLiberalsSay          0.031214\n",
       "ShitPoliticsSays         0.030576\n",
       "Showerthoughts           0.029432\n",
       "dadjokes                 0.033793\n",
       "esist                    0.024038\n",
       "funny                    0.041057\n",
       "legaladvice              0.032890\n",
       "mildlyinteresting        0.050222\n",
       "todayilearned            0.045959\n",
       "worldpolitics            0.031766\n",
       "Name: subreddit, dtype: float64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "(df[df.index.isin(to_keep)]['subreddit'].value_counts()/df.iloc[range(217846)]['subreddit'].value_counts()).dropna()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "62e0d6d3bc4f411a59808a0be8a264bf74dacde0b88c0c03b563112961a530da"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
